{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = 'data/tvpl.csv'\n",
    "df_raw = pd.read_csv(PATH_DATA, encoding='utf-8-sig')\n",
    "\n",
    "# Định dạng cột 'Ngày ban hành'\n",
    "df_raw['Ngày ban hành'] = pd.to_datetime(df_raw['Ngày ban hành'], format='%d/%m/%Y').dt.strftime('ngày %d tháng %m năm %Y')  # định dạng cột 'ngày ban hành'\n",
    "\n",
    "# Loại bỏ các hàng ngoại lệ\n",
    "list_remove = [9,369,2936,3789,4630,5740,6707]                      \n",
    "df_raw = df_raw.drop(index=list_remove).reset_index(drop=True)\n",
    "\n",
    "column_vb = 'Nội dung'\n",
    "column_qh = 'Mối quan hệ'\n",
    "\n",
    "df_raw.info()\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đối tượng chứa các hàm xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import enchant\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "class tvpl_function:\n",
    "    def __init__(self):\n",
    "        self.pattern = 'aàảãáạăằẳẵắặâầẩẫấậeèẻẽéẹêềểễếệiìỉĩíịoòỏõóọôồổỗốộơớờởỡợuùủũúụưừửữứựyỳỷỹýỵđ'\n",
    "\n",
    "        self.words_en = enchant.Dict(\"en_US\")\n",
    "        \n",
    "        self.specialCharset = '!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "\n",
    "        self.words = []\n",
    "        with open(\"../data/words.txt\", \"r\", encoding='utf-8') as file:\n",
    "            for f in file:\n",
    "                word = json.loads(f)\n",
    "                self.words.append(word[\"text\"])\n",
    "\n",
    "        self.syllables = []\n",
    "        with open(\"../data/syllable.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "            for line in file:\n",
    "                self.syllables.append(line.strip())\n",
    "                \n",
    "        self.mapping={\n",
    "            'óa':'oá', 'òa':'oà', 'ỏa':'oả', 'õa':'oã', 'ọa':'oạ',\n",
    "            'óe':'oé', 'òe':'oè', 'ỏe':'oẻ', 'õe':'oẽ', 'ọe':'oẹ',\n",
    "            'úy':'uý', 'ùy':'uỳ', 'ủy':'uỷ', 'ũy':'uỹ', 'ụy':'uỵ',\n",
    "            'úâ':'uấ', 'ùâ':'uầ', 'ủâ':'uẩ', 'ũâ':'uẫ', 'ụâ':'uậ',\n",
    "            'úe':'ué', 'ùe':'uè', 'ủe':'uẻ', 'ũe':'uẽ', 'ụe':'uẹ',\n",
    "            'úê':'uế', 'ùê':'uề', 'ủê':'uể', 'ũê':'uễ', 'ụê':'uệ',\n",
    "            'úơ':'uớ', 'ùơ':'uờ', 'ủơ':'uở', 'ũơ':'uỡ', 'ụơ':'uợ',\n",
    "            'úô':'uố', 'ùô':'uồ', 'ủô':'uổ', 'ũô':'uỗ', 'ụô':'uộ',\n",
    "            'iá':'ía', 'ià':'ìa', 'iả':'ỉa', 'iã':'ĩa', 'iạ':'ịa',\n",
    "            'yá':'ýa', 'yà':'ỳa', 'yả':'ỷa', 'yã':'ỹa', 'yạ':'ỵa',\n",
    "            'uá':'úa', 'uà':'ùa', 'uả':'ủa', 'uã':'ũa', 'uạ':'ụa',\n",
    "            'ưá':'ứa', 'ưà':'ừa', 'ưả':'ửa', 'ưã':'ữa', 'ưạ':'ựa',\n",
    "            'ứơ':'ướ', 'ừơ':'ườ', 'ửơ':'ưở', 'ữơ':'ưỡ', 'ựơ':'ượ',\n",
    "            'íê':'iế', 'ìê':'iề', 'ỉê':'iể', 'ĩê':'iễ', 'ịê':'iệ',\n",
    "            'ýê':'yế', 'ỳê':'yề', 'ỷê':'yể', 'ỹê':'yễ', 'ỵê':'yệ',\n",
    "            'uí':'úi', 'uì':'ùi', 'uỉ':'ủi', 'uĩ':'ũi', 'uị':'ụi',\n",
    "            'aó':'áo', 'aò':'ào', 'aỏ':'ảo', 'aõ':'ão', 'aọ':'ạo',\n",
    "            'qúa':'quá', 'qùa':'quà', 'qủa':'quả', 'qũa':'quã', 'qụa': 'quạ',\n",
    "            'Qúa':'Quá', 'Qùa':'Quà', 'Qủa':'Quả', 'Qũa':'Quã', 'Qụa': 'Quạ', \n",
    "            'gía':'giá', 'gìa':'già', 'gỉa':'giả', 'gĩa':'giã', 'gịa': 'giạ',\n",
    "            'Gía':'Giá', 'Gìa':'Già', 'Gỉa':'Giả', 'Gĩa':'Giã', 'Gịa': 'Giạ',\n",
    "        }\n",
    "        \n",
    "        self.type_documents =['Hiến_pháp', 'Bộ_luật', 'Luật', 'Pháp_lệnh', 'Lệnh', 'Nghị_quyết', 'Nghị_quyết liên_tịch', 'Nghị_định', 'Quyết_định', 'Thông_tư', 'Thông_tư liên_tịch', 'Chỉ_thị']\n",
    "        \n",
    "\n",
    "    # chuẩn hóa bảng mã tiếng việt\n",
    "    # Tạo ra từ điện bộ kí tự\n",
    "    def load_DictChar(self):\n",
    "        dic = {}\n",
    "        char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "            '|')\n",
    "        charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "            '|')\n",
    "        for i in range(len(char1252)):\n",
    "            dic[char1252[i]] = charutf8[i]\n",
    "        return dic\n",
    "    \n",
    "    # Chuyển đổi mã kí tự 1252 sang UTF-8\n",
    "    def covert_unicode(self, txt):\n",
    "        dicchar = self.load_DictChar()\n",
    "        return re.sub(\n",
    "            r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "            lambda x: dicchar[x.group()], txt) \n",
    "\n",
    "    # xóa phần không cần thiết trong văn bản\n",
    "    def removeUnnecessaryPart(self, row):\n",
    "        for i, line in enumerate(row.splitlines()):\n",
    "            if re.match(r\"^(PHẦN PHỤ LỤC|DANH MỤC PHỤ LỤC)\", line) or re.match(r\"^phụ lục\", line.lower()) or re.match(r\"^(\\s|\\t)*PHỤ LỤC\", line):\n",
    "                row = '\\n'.join(row.splitlines()[:i])\n",
    "                break     \n",
    "        \n",
    "        return row\n",
    "\n",
    "    #  Tìm và thay thế các ký tự không in được trong text thành khoảng trắng\n",
    "    def  replace_non_printable_chars(self, row):\n",
    "        return  ''.join(char if char in string.printable or char.lower() in self.pattern else ' ' for char in row)\n",
    "                \n",
    "    def data_processing(self, row):\n",
    "        row = self.covert_unicode(row)                          # Chuẩn hóa bảng mã kí \n",
    "        row = self.removeUnnecessaryPart(row)                   # Loại bỏ phần không cần thiết\n",
    "        row = self.replace_non_printable_chars(row)             # Thay thế các chuỗi không in được thành khoảng trắng\n",
    "        \n",
    "        result_line = []\n",
    "        for line in row.splitlines():           \n",
    "            if line.strip():\n",
    "                line = self.sentence_processing(line)           # Tách âm tiết bị dính nhau\n",
    "                line = self.split_word(line)                    # Tách câu, tách từ tiếng              \n",
    "                result_line.append(line)\n",
    "        \n",
    "        row = \"\\n\\n\".join(result_line)\n",
    "        row = self.highlight_object(row)\n",
    "\n",
    "        return row\n",
    "\n",
    "    # Tách câu, tách từ tiếng \n",
    "    def split_word(self, sentence):\n",
    "        pattern = re.compile(r'\\d{1,4}(/|-)\\d{1,4}(/|-)?\\w{0,7}(-\\w{2,4})?|\\d{1,4}(/|-)\\w{2,7}(-\\w{2,4})?')\n",
    "        result = ''\n",
    "        i_start = 0\n",
    "        str_list =  sentence.split()\n",
    "        \n",
    "        for i, word in enumerate(sentence.split()):\n",
    "            if pattern.match(word):\n",
    "                text = ' '.join(str_list[i_start:i])\n",
    "                text = ViTokenizer.tokenize(text)\n",
    "                result += f'{text} {str_list[i]} '\n",
    "                i_start = i + 1\n",
    "\n",
    "        if i_start < len(str_list):\n",
    "            text = ' '.join(str_list[i_start:])\n",
    "            text = ViTokenizer.tokenize(text)\n",
    "            result += text\n",
    "\n",
    "        return result.strip()   \n",
    "\n",
    "    # Xử lý câu\n",
    "    def sentence_processing(self, sentence):\n",
    "        result_sentence = []\n",
    "        sentence = self.word_processing(sentence)           # Xử lý từ cơ bản\n",
    "\n",
    "        for word in sentence.split():                  \n",
    "            # Nếu từ không chứa kí tự, từ có nghĩa, là số ký hiệu hoặc là từ tiếng anh thì bỏ qua\n",
    "            if (len(word) == 1\n",
    "                    or any(char in word for char in self.specialCharset)\n",
    "                    or any(char in word.lower() for char in [\"f\",\"j\",\"w\",\"z\"])\n",
    "                    or any(char.isnumeric() for char in word)\n",
    "                    or self.words_en.check(word) \n",
    "                    or self.syllable_check(word) \n",
    "                    ):\n",
    "                result_sentence.append(word)\n",
    "                continue\n",
    "\n",
    "            # Từ có nghĩa nhưng có 2 chữ giống nhau liên tiếp (vd: hoaang, luuật)\n",
    "            word = self.double_char(word)\n",
    "            if self.syllable_check(word):   # xét từ có nghĩa chưa\n",
    "                result_sentence.append(word)\n",
    "                continue\n",
    "\n",
    "            check = True\n",
    "            #Kiểm tra cặp từ có nghĩa trong từ điển\n",
    "            for i in range(1, len(word)-1):\n",
    "                text = word[:i] + \" \" + word[i:]\n",
    "                if self.dictionary_check(text):\n",
    "                    check = False\n",
    "                    break\n",
    "                \n",
    "            # Nếu không có cặp từ có nghĩa\n",
    "            if check:\n",
    "                text = self.split_syllable(word)   # text = text (được tách ra)/ False (không được tách)\n",
    "\n",
    "            # Xử lý các âm tiết bị lỗi dính nhau (các trường hợp chữ viết tắt và sai chính tả -> False)\n",
    "            result_sentence.append(text if text else word) # nếu False thì từ được giữ nguyên\n",
    "\n",
    "        return ' '.join(result_sentence)\n",
    "    \n",
    "    # Xử lý từ\n",
    "    def word_processing(self, sentence):\n",
    "        result = []\n",
    "        pattern = re.compile(r'\\d{1,4}(/|-)\\d{1,4}(/|-)?\\w{0,7}(-\\w{2,4})?|\\d{1,4}(/|-)\\w{2,7}(-\\w{2,4})?')\n",
    "        for word in sentence.split():\n",
    "            word = self.standardize_Tone(word)  # Chuẩn hóa thanh điệu\n",
    "            word = self.chuan_hoa_y_i(word)     # Chuẩn hóa y/i\n",
    "\n",
    "            if word.isupper() and not pattern.match(word):\n",
    "                word = word.capitalize()\n",
    "\n",
    "            for i in self.specialCharset:\n",
    "                if ('/' in word or '-' in word) and pattern.match(word):\n",
    "                    continue\n",
    "                if i in word:\n",
    "                    word = word.replace(i, f\" {i} \")    # Tách các kí tự đặc biệt \n",
    "            result.append(word)\n",
    "        \n",
    "        return ' '.join(result).replace('  ', ' ').strip()\n",
    "\n",
    "\n",
    "    # Chuẩn hóa y và i (vd: tỷ lệ -> tỉ lệ, bác sỹ -> bác sĩ)\n",
    "    def chuan_hoa_y_i(self, word):\n",
    "        set_yi ={1: 'yýỳỷỹỵ', 2: 'iíìỉĩị'}\n",
    "        index_yi = None\n",
    "        index_setyi = None\n",
    "        for i in range(6):\n",
    "            if set_yi[1][i] in word or set_yi[2][i] in word:\n",
    "                index_yi = word.index(set_yi[1][i]) if set_yi[1][i] in word else word.index(set_yi[2][i])\n",
    "                index_setyi = i\n",
    "                break\n",
    "\n",
    "        if index_yi is not None:\n",
    "            if len(word) == 1 and word in set_yi[2]:\n",
    "                word = set_yi[1][index_setyi]\n",
    "            elif (len(word) > 1 and index_yi == len(word) - 1 and word[index_yi] in set_yi[1] \n",
    "            and word[:index_yi] in ['b','c','ch','d','đ','g','gh','h','k','kh','l','m','n','ng','ngh','nh','p','ph','r','s','t','th','tr','v','x']):\n",
    "                word = word[:index_yi] + set_yi[2][index_setyi]\n",
    "\n",
    "        return word\n",
    "\n",
    "    # Trả kết quả xử lý tách các âm tiết dính nhau\n",
    "    def split_syllable(self, syllable):  \n",
    "        memories = []\n",
    "        while syllable != '':\n",
    "            text_len = len(syllable)    # Độ dài từ hiện tại\n",
    "            memory = []                 # Chứa các từ có nghĩa \n",
    "            queue = ''                  # Cập nhật các từ\n",
    "\n",
    "            for i in range(text_len):\n",
    "                # Xử lý từ có nghĩa (vd: nóng -> memory = [nó, nón, nóng])\n",
    "                queue += syllable[i]\n",
    "                \n",
    "                # Lọc ra cá kí tự đứng 1 mình, trừ các từ có thể\n",
    "                if len(queue) == 1 and queue not in ['ả', 'ế', 'ô', 'ố', 'ổ', 'y', 'ý', 'ỷ', 'ủ']:\n",
    "                    continue\n",
    "\n",
    "                if self.syllable_check(queue) or self.dictionary_check(queue):\n",
    "                    memory.append(queue)\n",
    "            \n",
    "            # Nếu memory có chứa các từ có nghĩa\n",
    "            if memory:\n",
    "                memories.append(memory)\n",
    "                syllable = syllable[len(memory[-1]):]     # Loại bỏ từ có nghĩa trong chuỗi syllable và xét tiếp theo vòng lặp while\n",
    "            # Nếu không\n",
    "            else:\n",
    "                # Nếu xét cả chuỗi không có từ nào hoặc chỉ 1 từ có nghĩa trong chuỗi -> False\n",
    "                if memories and len(memories[0]) > 1:\n",
    "                    # kiểm tra chuỗi từ trước có 2 từ trở lên thì ghép chữ cuối cùng của chuỗi từ đó [-1]  \n",
    "                    for j in range(len(memories), 0, -1):\n",
    "                        # Vd: hoặcđiago -> memories = [['cá', 'các', 'cách'],['i']] --- syllable = 'ệp'\n",
    "                        if len(memories[j-1]) >= 2:\n",
    "                            syllable = memories[j-1].pop(-1)[-1] + ''.join(c[-1] for c in memories[j:]) + syllable\n",
    "                            memories = memories[:j]\n",
    "                            break\n",
    "                else:\n",
    "                    return False\n",
    "        \n",
    "        return ' '.join(i[-1] for i in memories)\n",
    "\n",
    "    # kiểm tra từ hoặc cụm từ có trong từ điển\n",
    "    def dictionary_check(self, text):\n",
    "        return text.lower() in self.words\n",
    "    \n",
    "    # kiểm tra âm tiết có trong từ điển\n",
    "    def syllable_check(self, syllable):\n",
    "        return syllable.lower() in self.syllables\n",
    "\n",
    "    # xóa các kí tự lặp (trừ \"o\")\n",
    "    def double_char(self, word):\n",
    "        result = word[0]  # Khởi tạo result với ký tự đầu tiên của word\n",
    "        for i in range(1, len(word)):  # Bắt đầu vòng lặp từ chỉ số 1\n",
    "            if result[-1] == word[i] and word[i] != 'o':\n",
    "                continue\n",
    "            result += word[i]\n",
    "\n",
    "        return result\n",
    "\n",
    "    # Chuẩn hóa thanh điệu \n",
    "    def standardize_Tone(self, word):  \n",
    "        if word != \"gịa\" and word != \"quốc\":\n",
    "            for key, value in self.mapping.items():\n",
    "                word = word.replace(key, value)\n",
    "        return word\n",
    "    \n",
    "    # làm đối tượng nổi bật\n",
    "    def highlight_object(self, sentence):\n",
    "        for key in self.type_documents:             \n",
    "            if key.lower() in sentence.lower():\n",
    "                i_start = sentence.lower().index(key.lower())\n",
    "                i_end = i_start + len(key)\n",
    "                text = sentence[i_start : i_end]\n",
    "                sentence = sentence.replace(text, key)    \n",
    "\n",
    "        \n",
    "        pattern = r'(\\w)_(\\w)'\n",
    "        matches = re.findall(pattern, sentence)\n",
    "        matches = list(set(matches))\n",
    "        for match in matches:\n",
    "            if match[0].islower() and match[1].isupper():\n",
    "                key_word = '_'.join(match)\n",
    "                sentence = sentence.replace(key_word, key_word.lower())\n",
    "\n",
    "        if 'pháp lệnh' in sentence.lower():\n",
    "            start_index = sentence.lower().index('pháp lệnh')\n",
    "            end_index = start_index + len('pháp lệnh')\n",
    "            if sentence[start_index-1] == '_':\n",
    "                sentence = sentence[:start_index - 1] + \" \" +sentence[start_index:]\n",
    "            sentence = sentence[:start_index] + 'Pháp_lệnh' + sentence[end_index:]\n",
    "        \n",
    "\n",
    "        return sentence\n",
    "    \n",
    "\n",
    "vb = tvpl_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xử lý văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df[column_vb] = df[column_vb].apply(vb.data_processing)\n",
    "\n",
    "# Đặt tên theo cấu trúc '[loại văn bản] + [số hiệu] + [ngày ban hành] + [cơ quan ban hành]' ở dòng đầu tiên của mỗi văn bản\n",
    "for i in range(len(df)):\n",
    "    title = ViTokenizer.tokenize(df.loc[i, 'Loại văn bản']) + ' số ' + df.loc[i, 'Số hiệu'] + ' ' + df.loc[i, 'Ngày ban hành'] + ' của ' + ViTokenizer.tokenize(df.loc[i, 'Cơ quan ban hành'])\n",
    "    df.at[i, column_vb] = title.strip().capitalize() + '\\n\\n' + df.at[i, column_vb]\n",
    "\n",
    "# Xử lý cột \"Mối quan hệ\" (chuẩn hóa cột 'Mối quan hệ')\n",
    "for i in range(len(df)):\n",
    "    row_qh = df.loc[i, column_qh]\n",
    "    row_qh = row_qh.replace(\"'bị sửa đổi, bổ sung'\", \"'được sửa_đổi , bổ_sung'\")\n",
    "    row_qh = {key.strip().capitalize(): [v.strip() for v in value] for key, value in eval(row_qh).items()}\n",
    "    for key, values in row_qh.items():\n",
    "        for i_value in range(len(values)):\n",
    "            values[i_value] = vb.data_processing(values[i_value])  \n",
    "        \n",
    "    df.at[i, column_qh] = {ViTokenizer.tokenize(key): values for key, values in row_qh.items()}\n",
    "\n",
    "\n",
    "\n",
    "# Xuất file csv\n",
    "df.to_csv(\"data/tvpl_processing.csv\", encoding=\"utf-8-sig\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thống kê các tên văn bản có trong văn bản chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_type = {}\n",
    "for i, row in enumerate(df[column_vb]):\n",
    "    for key in vb.type_documents:\n",
    "        count = row.count(f\" {key} \")\n",
    "        if key not in dict_type:\n",
    "            dict_type[key] = count\n",
    "        else: \n",
    "            dict_type[key] = dict_type[key] + count\n",
    "\n",
    "print(len(dict_type))\n",
    "dict_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xác định các nhãn quan hệ trong tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_list = []\n",
    "\n",
    "for i, row_dict in enumerate(df[column_qh]):\n",
    "    for key in row_dict.keys():\n",
    "        if key not in label_list:\n",
    "            label_list.append(key)\n",
    "\n",
    "label_list = [key for key in label_list]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gán nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_vb = 'Nội dung'\n",
    "column_qh = 'Mối quan hệ'\n",
    "\n",
    "df = pd.read_csv('data/tvpl_processing.csv', encoding='utf-8-sig')\n",
    "df[column_qh] = df.apply(lambda x: eval(x[column_qh]), axis=1)\n",
    "\n",
    "label_dict = {\n",
    "    'Được sửa_đổi , bổ_sung': 'DSD',\n",
    "    'Bị thay_thế': 'BTT',\n",
    "    'Dẫn_chiếu': 'DC',\n",
    "    'Căn_cứ': 'CC',\n",
    "    'Được hướng_dẫn': 'DHD',\n",
    "    'Hết hiệu_lực': 'HHL',\n",
    "}\n",
    "key_dict = {\n",
    "    'Hiến_pháp': 'HP',\n",
    "    'Bộ_luật': 'BL',\n",
    "    'Luật': 'LT',\n",
    "    'Pháp_lệnh': 'PL',\n",
    "    'Lệnh': 'LH',\n",
    "    'Quyết_định': 'QĐ',\n",
    "    'Nghị_định': 'NĐ',\n",
    "    'Nghị_quyết': 'NQ',\n",
    "    'Nghị_quyết liên_tịch': 'NQLT',\n",
    "    'Thông_tư': 'TT',\n",
    "    'Thông_tư liên_tịch': 'TTLT',\n",
    "    'Chỉ_thị': 'CT',\n",
    "}\n",
    "\n",
    "# check có trong quan hệ\n",
    "def check_relationship(line, entity, row_qh):\n",
    "    cc_check = ['căn_cứ ' + entity, 'căn_cứ vào ' + entity]\n",
    "    if  any(cc.lower() in line.lower() for cc in cc_check):\n",
    "        return 'CC'\n",
    "    \n",
    "    qh = ''\n",
    "    pattern = r'Sửa_đổi , bổ_sung( [^.;()]+)?' + rf'{entity}'\n",
    "    if re.search(pattern, line):\n",
    "        qh = 'DSD'\n",
    "    pattern = r'(tại|theo)+ ([^.;()]+ )?'+rf'{entity}'\n",
    "    if re.search(pattern, line):\n",
    "        qh = 'DC'\n",
    "\n",
    "    pattern = rf'{entity}' + r'( [^.;()]+)?được sửa_đổi , bổ_sung '\n",
    "    if re.search(pattern, line):\n",
    "        qh = 'DSD'\n",
    "\n",
    "    pattern = rf'{entity}' + r'( [^.;()]+)? hết hiệu_lực '\n",
    "    if re.search(pattern, line):\n",
    "        qh = 'HHL'\n",
    "\n",
    "    if qh:\n",
    "        return qh\n",
    "\n",
    "    for key, list_value in row_qh.items():\n",
    "        for value in list_value:\n",
    "            if entity.lower() in value.lower():\n",
    "                return label_dict[key]\n",
    "    return 'None'\n",
    "\n",
    "def check_entity(child_line, list_value):\n",
    "    # chuẩn hóa danh sách các đối tượng của mối quan hệ    \n",
    "    list_qh = []\n",
    "    for value in list_value:\n",
    "        list_qh.extend(value)\n",
    "\n",
    "    # Xét theo cấu trúc có số kí hiệu\n",
    "    if ('/' in child_line or '-' in child_line or re.findall(r'(?:năm |tháng |ngày )(?:\\d{1,2}|\\d{4})', child_line)) and re.findall(r'(\\d+)+', child_line): \n",
    "        pattern = re.compile(r'((?:(?!ngày|tháng|năm|số)\\w+[\\s_,]+)+)?(_số|số)?\\s?(\\d+?[\\w]+(?:(?:/|-)+(?:\\d|\\w)+)+)?\\s?((?:năm |tháng |ngày |)(?:\\d{4}|\\d{1,2}))?((?: năm | tháng |[-]|[/])(?:\\d{4}|\\d{1,2}))?((?: năm |[-]|[/])\\d{4})?')\n",
    "        matches = pattern.findall(child_line)\n",
    "\n",
    "        entity = []\n",
    "        for match in matches:\n",
    "            match = [en for en in match if en]\n",
    "            if match and len(match) > 1:\n",
    "                entity.append(match)\n",
    "\n",
    "        if entity:\n",
    "            entity = ' '.join(entity[0]).replace('  ', ' ').replace(' -', '-').replace(' /', '/')\n",
    "            return entity\n",
    "    \n",
    "    # Nếu không có, Xét theo các phần tử trong danh sách các đối tượng\n",
    "    Entity = []\n",
    "    check = True\n",
    "    for e in child_line.split():\n",
    "        if not Entity:\n",
    "            Entity.append(e)\n",
    "            continue\n",
    "        text = ''\n",
    "        for qh in list_qh:\n",
    "            text = ' '.join(Entity) + f' {e}'\n",
    "            if text.lower() in qh.lower():\n",
    "                Entity.append(e)\n",
    "                check = False\n",
    "                break\n",
    "        if len(text.split()) != len(Entity):\n",
    "            break\n",
    "\n",
    "    if len(Entity) == 1 and check:\n",
    "        return False\n",
    "\n",
    "    if Entity:\n",
    "        Entity = ' '.join(Entity)\n",
    "        if Entity[-1] in vb.specialCharset and not (Entity[-1] == ')' and '(' in Entity):\n",
    "            Entity = Entity[:-1].strip()\n",
    "\n",
    "        return Entity\n",
    "\n",
    "    return False\n",
    "\n",
    "def labelling(line, key, row_qh):\n",
    "\n",
    "    # Hiến pháp được xử lý riêng vì đây là trường hợp đặc biệt\n",
    "    if key == 'Hiến_pháp':\n",
    "        pattern = rf'({key}) '+ r'(nước Cộng_hoà xã_hội chủ_nghĩa Việt_nam)?\\s?(\\d+|năm \\d+)?'\n",
    "        matches = re.findall(pattern, line)\n",
    "        for match in matches:\n",
    "            match = [m for m in match if m]\n",
    "            if match and len(match) > 1:\n",
    "                Entity = ' '.join(match).strip()\n",
    "                qh = check_relationship(line, Entity, row_qh)\n",
    "                label_Entity = f'<{key_dict[key]} rel=\"{qh}\">' + f' {Entity} ' + f\"</{key_dict[key]}>\"\n",
    "                line = line.replace(Entity, label_Entity)\n",
    "    else:\n",
    "        # tách các đối tượng trên 1 dòng thành các phần tử theo loại văn bản\n",
    "        list_child_line = line.split(key)\n",
    "        if len(list_child_line) > 1:\n",
    "            for i_child_line in range(1, len(list_child_line)): \n",
    "                qh = ''\n",
    "                Entity = ''\n",
    "                child_line = list_child_line[i_child_line]\n",
    "                child_line = child_line.strip()\n",
    "\n",
    "                if child_line:\n",
    "                    first_child_line = child_line.split()[0]\n",
    "                    # Lọc các xong có chứa ký tự không liên quan\n",
    "                    if not (any(True for wrong in ['này', 'khác', 'có'] if wrong == first_child_line) or \n",
    "                        (list_child_line[i_child_line - 1].split() and list_child_line[i_child_line - 1].split()[-1] in key_dict.keys()) or\n",
    "                        first_child_line in vb.specialCharset or\n",
    "                        (first_child_line == 'liên_tịch' and key in ['Nghị_định', 'Thông_tư'])):\n",
    "                    \n",
    "                        # Tìm đối tượng được nhắc tới\n",
    "                        entity = check_entity(child_line, row_qh.values())\n",
    "                        if not entity:\n",
    "                            continue\n",
    "                        key_plus = key + ' '\n",
    "                        if entity[0] == '_':\n",
    "                            key_plus = key\n",
    "                        Entity = key_plus + entity\n",
    "\n",
    "                        # Tìm quan hệ giữa đối tượng được nhắc tới trong văn bản đang xét\n",
    "                        qh = check_relationship(line, Entity, row_qh)\n",
    "\n",
    "                        label_Entity = f'<{key_dict[key]} rel=\"{qh}\">' + f' {Entity} ' + f\"</{key_dict[key]}>\"\n",
    "                        child_line_label = child_line.replace(entity, label_Entity)\n",
    "                        line = line.replace(key_plus + child_line, child_line_label)\n",
    "                        \n",
    "    return line\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "df1 = df.copy()\n",
    "\n",
    "for i in range(len(df1)):\n",
    "\n",
    "    row_vb = df1.loc[i, column_vb]\n",
    "    row_qh = df1.loc[i, column_qh]\n",
    "\n",
    "    line_total = []\n",
    "    line_total.extend(row_vb.splitlines()[0:2])\n",
    "    for line in row_vb.splitlines()[2:]:\n",
    "        for key in key_dict.keys():\n",
    "            if key in line:\n",
    "                line = labelling(line, key, row_qh)\n",
    "        line_total.append(line)\n",
    "    df1.at[i, column_vb] = '\\n'.join(line_total)\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XUẤT TẬP DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df1\n",
    "for i in range(len(_df)):\n",
    "    with open(f'data/source_label/vb_{i}.xml', 'w', encoding='utf-8') as file:\n",
    "        for line in _df.loc[i, column_vb].splitlines():\n",
    "            file.write(line + '\\n')\n",
    "        \n",
    "    \n",
    "# with open('text.txt', 'w', encoding='utf-8') as file:\n",
    "#     for line in _df.loc[2, column_vb].splitlines():\n",
    "#         file.write(line + '\\n')\n",
    "\n",
    "# Xuất file csv\n",
    "df1.to_csv(\"data/tvpl_label.csv\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
